{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-whisper\n",
    "!pip install deep-translator\n",
    "!pip install groq\n",
    "!pip install gradio\n",
    "!pip install diffusers transformers gradio accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: add the theme  featrue in above  Audio Transcription, Translation, and Sentiment Analysis app and also need selectbox for sentiment and generated image\n",
    "import whisper\n",
    "import os\n",
    "import gradio as gr\n",
    "from groq import Groq\n",
    "from deep_translator import GoogleTranslator\n",
    "import pickle\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "# Replace with your actual API key\n",
    "api_key =\"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\"\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "# Load the sentiment analysis model\n",
    "loaded_model = pickle.load(open('/content/hotel_review_sentiment_model.pkl', 'rb'))\n",
    "\n",
    "model_id1 = \"dreamlike-art/dreamlike-diffusion-1.0\"\n",
    "model_id2 = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id1, torch_dtype=torch.float16, use_safetensors=True)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"\"\"dreamlikeart, a grungy woman with rainbow hair, travelling between dimensions, dynamic pose, happy, soft eyes and narrow chin,\n",
    "extreme bokeh, dainty figure, long hair straight down, torn kawaii shirt and baggy jeans\n",
    "\"\"\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# Function to transcribe, translate, and analyze sentiment\n",
    "def process_audio(audio_path, sentiment_option, image_option):\n",
    "    if audio_path is None:\n",
    "        return \"Please upload an audio file.\", None, None, None\n",
    "\n",
    "    # Step 1: Transcribe audio\n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                file=(os.path.basename(audio_path), file.read()),\n",
    "                model=\"whisper-large-v3\",\n",
    "                language=\"ta\",\n",
    "                response_format=\"verbose_json\",\n",
    "            )\n",
    "        tamil_text = transcription.text\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during transcription: {str(e)}\", None, None, None\n",
    "\n",
    "    # Step 2: Translate Tamil to English\n",
    "    try:\n",
    "        translator = GoogleTranslator(source='ta', target='en')\n",
    "        translation = translator.translate(tamil_text)\n",
    "    except Exception as e:\n",
    "        return tamil_text, f\"An error occurred during translation: {str(e)}\", None, None\n",
    "\n",
    "    # Step 3: Analyze sentiment (if selected)\n",
    "    sentiment = None\n",
    "    if sentiment_option == \"Analyze Sentiment\":\n",
    "        try:\n",
    "            sentiment = loaded_model.predict([translation])[0]\n",
    "        except Exception as e:\n",
    "            return tamil_text, translation, f\"An error occurred during sentiment analysis: {str(e)}\", None\n",
    "\n",
    "    # Step 4: Generate image (if selected)\n",
    "    image = None\n",
    "    if image_option == \"Generate Image\":\n",
    "        try:\n",
    "            model_id1 = \"dreamlike-art/dreamlike-diffusion-1.0\"\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(model_id1, torch_dtype=torch.float16, use_safetensors=True)\n",
    "            pipe = pipe.to(\"cuda\")\n",
    "            image = pipe(translation).images[0]\n",
    "        except Exception as e:\n",
    "            return tamil_text, translation, sentiment, f\"An error occurred during image generation: {str(e)}\"\n",
    "\n",
    "    return tamil_text, translation, sentiment, image\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(theme=gr.themes.Base()) as iface:\n",
    "    gr.Markdown(\"# Audio Transcription, Translation, and Sentiment Analysis\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            audio_input = gr.Audio(type=\"filepath\", label=\"Upload Audio File\")\n",
    "            sentiment_option = gr.Dropdown([\"Analyze Sentiment\", \"Skip Sentiment\"], label=\"Sentiment Analysis\", value=\"Analyze Sentiment\")\n",
    "            image_option = gr.Dropdown([\"Generate Image\", \"Skip Image\"], label=\"Image Generation\", value=\"Generate Image\")\n",
    "            submit_button = gr.Button(\"Process Audio\")\n",
    "        with gr.Column():\n",
    "            tamil_text_output = gr.Textbox(label=\"Tamil Transcription\")\n",
    "            translation_output = gr.Textbox(label=\"English Translation\")\n",
    "            sentiment_output = gr.Textbox(label=\"Sentiment\")\n",
    "            image_output = gr.Image(label=\"Generated Image\")\n",
    "\n",
    "    submit_button.click(\n",
    "        fn=process_audio,\n",
    "        inputs=[audio_input, sentiment_option, image_option],\n",
    "        outputs=[tamil_text_output, translation_output, sentiment_output, image_output]\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
